<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="content-type" content="text/html;charset=utf-8">
  <title>regression.py</title>
  <link rel="stylesheet" href="pycco.css">
</head>
<body>
<div id='container'>
  <div id="background"></div>
  
  <table cellspacing=0 cellpadding=0>
  <thead>
    <tr>
      <div class=docs><h1>regression.py</h1></th>
      <!--<div class=code></th>-->
    </tr>
  </thead>
  <tbody>
    <tr id='section-0'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>We hear about correlations every day.  Various health outcomes are
<a href="https://www.nber.org/reporter/spring03/health.html">correlated with socioeconomic
status</a>.  Iodine
supplementation in infants is <a href="https://www.ncbi.nlm.nih.gov/pubmed/15734706">correlated with higher
IQ</a>.  Models are
everywhere as well.  An object falling for t seconds moves .5gt^2
meters.  You can calculate correlation and built approximate models
using several techniques, but the simplest and most popular
technique by far is <strong> linear regression </strong>.  Let's see how it
works!</p>
<h3>County Health Rankings</h3>

<p>For our examples, we'll use the <a href="http://www.countyhealthrankings.org/">County Health
Rankings</a>.  Specifically,
we'll be looking at two datasets in this example: <a href="https://github.com/dataiap/dataiap/blob/master/datasets/county_health_rankings/ypll.csv">Years of
Potential Life
Lost</a>
and <a href="https://github.com/dataiap/dataiap/blob/master/datasets/county_health_rankings/additional_measures_cleaned.csv">Additional
Measures</a>.</p>
<p><a href="https://en.wikipedia.org/wiki/Years_of_potential_life_lost">Years of potential life lost</a> (YPLL) is an early mortality measure.  It
measures, across 100,000 people, how many total of the number of
years below the age of 75 that 100,000-person cohort loses.  For
example, if a person dies at age 73, they contribute 2 years to this
sum.  If they die at age 77, they contribute 0 years to the sum.
The YPLL for each 100,000 people, averaged across counties in the
United States is between 8000 and 9000 depending on the year.  The
file <code>ypll.csv</code> contains per-county YPLLs for the United States in
2011.</p>
<p>The additional measures (found in <code>additional_measures_cleaned.csv</code>)
contains all sorts of fun measures per county, ranging from the
percentage of people in the county with Diabetes to the population
of the county.</p>
<p>We're going to see which of the additional measures correlate
strongly with our mortality measure, and build predictive models for
county mortality rates given these additional measures.</p>
<h3>Loading the Rankings</h3>

<p>The two .csv files we've given you (ypll.csv and
additional_measures_cleaned.csv) went through quote a bit of
scrubbing already.  You can read <a href="https://github.com/dataiap/dataiap/blob/master/datasets/county_health_rankings/README">our notes on the
process</a>
if you're interested.</p>
<p>There's still a bit of work to do to load the data.  Some of the
YPLL values are marked "Unreliable" in a column ypll.csv, and we
don't want to train our regression on these.  Simiarly, some of the
columns of additional measures are empty, and we want to discard
these.  Finally, there is a row per state that summarizes the
state's statistics, and we want to ignore that row since we are
doing a county-by-county analysis. Here's a function, <code>read_csv</code>, that
will read the desired columns from one of the csv files.</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="kn">import</span> <span class="nn">csv</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-1'>
      
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="k">def</span> <span class="nf">read_csv</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="n">cols</span><span class="p">,</span> <span class="n">check_reliable</span><span class="p">):</span>
    <span class="n">reader</span> <span class="o">=</span> <span class="n">csv</span><span class="o">.</span><span class="n">DictReader</span><span class="p">(</span><span class="nb">open</span><span class="p">(</span><span class="n">file_name</span><span class="p">,</span> <span class="s">&#39;rU&#39;</span><span class="p">))</span>
    <span class="n">rows</span> <span class="o">=</span> <span class="p">{}</span> <span class="c"># map &quot;statename__countyname&quot; to the column names in cols</span>
    <span class="k">for</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">reader</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">check_reliable</span> <span class="ow">and</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;Unreliable&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s">&quot;x&quot;</span><span class="p">:</span> <span class="c"># discard unreliable data</span>
            <span class="k">continue</span>
        <span class="k">if</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;County&#39;</span><span class="p">]</span> <span class="o">==</span> <span class="s">&quot;&quot;</span><span class="p">:</span> <span class="c"># ignore the first entry for each state</span>
            <span class="k">continue</span>
        <span class="n">rname</span> <span class="o">=</span> <span class="s">&quot;</span><span class="si">%s</span><span class="s">__</span><span class="si">%s</span><span class="s">&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="s">&#39;State&#39;</span><span class="p">],</span> <span class="n">row</span><span class="p">[</span><span class="s">&#39;County&#39;</span><span class="p">])</span>
        <span class="k">try</span><span class="p">:</span> <span class="c"># if a row[col] is empty, float(row[col]) throws an exception</span>
            <span class="n">rows</span><span class="p">[</span><span class="n">rname</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="nb">float</span><span class="p">(</span><span class="n">row</span><span class="p">[</span><span class="n">col</span><span class="p">])</span> <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">cols</span><span class="p">]</span>
        <span class="k">except</span><span class="p">:</span>
            <span class="k">pass</span>
    <span class="k">return</span> <span class="n">rows</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-2'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>The function returns a dictionary mapping each state/county to the
columns in an array <code>cols</code>.  It handles all of the dirty data: data
marked unreliable, state-only data, and missing columns.</p>
<p>All of this data cleaning across different .csv files will result in
some county YPLL data to be dropped for being unreliable, and some
county additional measures data to be dropped for having missing
columns.  We need to do what database folks call a <strong> join </strong> between
the two county datasets so that only the counties remaining in both
datasets will be considered.  This is handled by the function
<code>get_arrs</code>:</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="kn">import</span> <span class="nn">numpy</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-3'>
      
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="k">def</span> <span class="nf">get_arrs</span><span class="p">(</span><span class="n">dependent_cols</span><span class="p">,</span> <span class="n">independent_cols</span><span class="p">):</span>
    <span class="n">ypll</span> <span class="o">=</span> <span class="n">read_csv</span><span class="p">(</span><span class="s">&quot;../datasets/county_health_rankings/ypll.csv&quot;</span><span class="p">,</span> <span class="n">dependent_cols</span><span class="p">,</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">measures</span> <span class="o">=</span> <span class="n">read_csv</span><span class="p">(</span><span class="s">&quot;../datasets/county_health_rankings/additional_measures_cleaned.csv&quot;</span><span class="p">,</span> <span class="n">independent_cols</span><span class="p">,</span> <span class="bp">False</span><span class="p">)</span>

    <span class="n">ypll_arr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">measures_arr</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">ypll</span><span class="o">.</span><span class="n">iteritems</span><span class="p">():</span>
        <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="n">measures</span><span class="p">:</span> <span class="c"># join ypll and measures if county is in both</span>
            <span class="n">ypll_arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">value</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
            <span class="n">measures_arr</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">measures</span><span class="p">[</span><span class="n">key</span><span class="p">])</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">ypll_arr</span><span class="p">),</span> <span class="n">numpy</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">measures_arr</span><span class="p">))</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-4'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>We return numpy arrays (matrices) with rows corresponding to
counties and columns corresponding to the columns we read from the
spreadsheet.  We can finally call the <code>get_arrs</code> function to laod
the desired columns from each file.</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="n">dependent_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;YPLL Rate&quot;</span><span class="p">]</span>
<span class="n">independent_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;Population&quot;</span><span class="p">,</span> <span class="s">&quot;&lt; 18&quot;</span><span class="p">,</span> <span class="s">&quot;65 and over&quot;</span><span class="p">,</span> <span class="s">&quot;African American&quot;</span><span class="p">,</span>
                    <span class="s">&quot;Female&quot;</span><span class="p">,</span> <span class="s">&quot;Rural&quot;</span><span class="p">,</span> <span class="s">&quot;%Diabetes&quot;</span> <span class="p">,</span> <span class="s">&quot;HIV rate&quot;</span><span class="p">,</span>
                    <span class="s">&quot;Physical Inactivity&quot;</span> <span class="p">,</span> <span class="s">&quot;mental health provider rate&quot;</span><span class="p">,</span>
                    <span class="s">&quot;median household income&quot;</span><span class="p">,</span> <span class="s">&quot;</span><span class="si">% hi</span><span class="s">gh housing costs&quot;</span><span class="p">,</span>
                    <span class="s">&quot;</span><span class="si">% F</span><span class="s">ree lunch&quot;</span><span class="p">,</span> <span class="s">&quot;</span><span class="si">% c</span><span class="s">hild Illiteracy&quot;</span><span class="p">,</span> <span class="s">&quot;% Drive Alone&quot;</span><span class="p">]</span>

<span class="n">ypll_arr</span><span class="p">,</span> <span class="n">measures_arr</span> <span class="o">=</span> <span class="n">get_arrs</span><span class="p">(</span><span class="n">dependent_cols</span><span class="p">,</span> <span class="n">independent_cols</span><span class="p">)</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-5'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>Phew.  That sucked.  Let's look at the data!</p>
      </div>
      
    </tr><tr id='section-6'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <h3>Look at a Scatterplot</h3>

<p>Like we did during hypothesis testing, our first step is to look at
the data to identify correlations.  The best visualization to
identify correlations is a scatterplot, since that shows us the
relationship between a potentially dependent variable (ypll) and an
independent variable like % diabetes.</p>
<p>Let's start by looking at scatterplots of ypll versus three
potentially correlated variables: % of a community that has
diabetes, % of the community under the age of 18, and median income.</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>

<span class="n">subplot</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">311</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">measures_arr</span><span class="p">[:,</span><span class="mi">6</span><span class="p">],</span> <span class="n">ypll_arr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#1f77b4&quot;</span><span class="p">)</span> <span class="c"># 6 = diabetes</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;ypll vs. </span><span class="si">% o</span><span class="s">f population with diabetes&quot;</span><span class="p">)</span>

<span class="n">subplot</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">312</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">measures_arr</span><span class="p">[:,</span><span class="mi">1</span><span class="p">],</span> <span class="n">ypll_arr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#1f77b4&quot;</span><span class="p">)</span> <span class="c"># 1 = age</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;ypll vs. % population less than 18 years of age&quot;</span><span class="p">)</span>

<span class="n">subplot</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">313</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">measures_arr</span><span class="p">[:,</span><span class="mi">10</span><span class="p">],</span> <span class="n">ypll_arr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#1f77b4&quot;</span><span class="p">)</span> <span class="c"># 10 = income</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;ypll vs. median household income&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">&#39;figures/three-scatters.png&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s">&#39;png&#39;</span><span class="p">)</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-7'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>Your plots should look something like this:</p>
<p><img alt="YPLL vs. population with diabetes, population less than 18 years of age, and median household income" src="figures/three-scatters.png" /></p>
<p>We picked these three examples because they show visual evidence of three forms of correlation:
 * In the first plot, we can see that when the percentage of people
 in a county with diabetes is higher so is the mortality rate
 (YPLL)---evidence of a positive correlation.
 * The second plot looks like a blob.  It's hard to see a
 relationship between mortality and the fraction of people under the
 age of 18 in a community.
 * The final plot shows evidence of negative correlation.  Counties
 with higher median incomes appear to have lower mortality rates.</p>
<p><strong> Exercise </strong> Look at scatter plots of other variables vs. YPLL.
We found the percent of children eligible for school lunch to be
alarmingly correlated with YPLL!</p>
<h3>Your First Regression</h3>

<p>It's time we turn the intuition from our scatterplots into math!
We'll do this using the <code>ols</code> module, which stands for <strong> ordinary
least squares </strong> regression.  Let's run a regression for YPLL vs. % Diabetes:</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="kn">import</span> <span class="nn">ols</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">ypll_arr</span><span class="p">,</span> <span class="n">measures_arr</span><span class="p">[:,</span><span class="mi">6</span><span class="p">],</span> <span class="s">&quot;YPLL Rate&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s">&quot;% Diabetes&quot;</span><span class="p">])</span> <span class="c"># 6 = diabetes</span>
<span class="n">model</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-8'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>As you can see, running the regression is simple, but interpreting
the output is tougher.  Here's the output of <code>model.summary()</code> for
the YPLL vs. % Diabetes regression:</p>
<pre><code> ======================================================================  
 Dependent Variable: YPLL Rate  
 Method: Least Squares  
 Date:  Fri, 23 Dec 2011

 Time:  13:48:11
 # obs:                2209
 # variables:         2
 ======================================================================
 variable     coefficient     std. Error      t-statistic     prob.
 ======================================================================
 const           585.126403      169.746288      3.447064      0.000577
 %Diabetes       782.976320      16.290678      48.062846      0.000000
 ======================================================================
 Models stats                         Residual stats
 ======================================================================
 R-squared             0.511405         Durbin-Watson stat   1.951279
 Adjusted R-squared    0.511184         Omnibus stat         271.354997
 F-statistic           2310.037134      Prob(Omnibus stat)   0.000000
 Prob (F-statistic)    0.000000         JB stat              559.729657
 Log likelihood       -19502.794993     Prob(JB)             0.000000
 AIC criterion         17.659389        Skew                 0.752881
 BIC criterion         17.664550        Kurtosis             4.952933
 ======================================================================
</code></pre>
<p>Let's interpret this:</p>
<ul>
<li>First, let's verify the statistical significance, to make sure
  nothing happened by chance, and that the regression is meaningful.
  In this case, <strong> Prob (F-statistic) </strong> is something very close to
  0, which is less than .05 or .01.  That is: we have statistical
  significance, and we an safely interpret the rest of the data.</li>
<li>The coefficients (called <strong> betas </strong>) help us understand what
  line best fits the data, in case we want to build a predictive
  model.  In this case <strong> const </strong> is 585.13, and <strong> %Diabetes </strong>
  has a coefficient of 782.98.  Thus, the line (y = mx + b) that
  best predicts YPLL from %Diabetes is: <strong> YPLL = (782.98 *
  %Diabetes) + 585.13</strong>.</li>
<li>To understand how well the line/model we've built from the data
  helps predict the data, we look at <strong> R-squared </strong>.  This value
  ranges from 0 (none of the change in YPLL is predicted by the
  above equation) to 1 (100% of the change in YPLL is predicted by
  the above equation).  In our case, 51% of the changes YPLL can be
  predicted by a linear equation on %Diabetes.</li>
</ul>
<p>Putting this all together, we've just discovered that, without
knowing the YPLL of a community, we can take data on the percentage
of people affected by diabetes, and roughly reconstruct 51% of the
YPLL's characteristics.</p>
<p>If you want to use the information in your regression to do more
than print a large table, you can access the data individually</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="k">print</span> <span class="s">&quot;p-value&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">Fpv</span>
<span class="k">print</span> <span class="s">&quot;coefficients&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span>
<span class="k">print</span> <span class="s">&quot;R-squared and adjusted R-squared:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">R2</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">R2adj</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-9'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>To better visualize the model we've built, we can also plot the line
we've calculated through the scatterplot we built before</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">6</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">subplot</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">measures_arr</span><span class="p">[:,</span><span class="mi">6</span><span class="p">],</span> <span class="n">ypll_arr</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#1f77b4&quot;</span><span class="p">)</span> <span class="c"># 6 = diabetes</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;ypll vs. </span><span class="si">% o</span><span class="s">f population with diabetes&quot;</span><span class="p">)</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-10'>
      
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="k">def</span> <span class="nf">best_fit</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span> <span class="c"># calculates y = mx + b</span>
    <span class="k">return</span> <span class="n">m</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">b</span>

<span class="n">line_ys</span> <span class="o">=</span> <span class="p">[</span><span class="n">best_fit</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">measures_arr</span><span class="p">[:,</span><span class="mi">6</span><span class="p">]]</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">measures_arr</span><span class="p">[:,</span> <span class="mi">6</span><span class="p">],</span> <span class="n">line_ys</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#ff7f0e&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">&#39;figures/scatter-line.png&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s">&#39;png&#39;</span><span class="p">)</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-11'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>That should result in a plot that looks something like</p>
<p><img alt="Scatterplot with best-fit line" src="figures/scatter-line.png" /></p>
<p>We can see that our line slopes upward (the beta coefficient in
front of the %Diabetes term is positive) indicating a positive
correlation.</p>
<p><strong> Exercise </strong> Run the correlations for percentage of population
under 18 years of age and median household income.</p>
<p>We got statistically significant results for all of these tests.
Median household income is negatively correlated (the slope beta is
-.13), and explains a good portion of YPLL (R-squared is .48).
Remember that we saw a blob in the scatterplot for percentage of
population under 18.  The regression backs this up: the R-squared of
.005 suggests little predictive power of YPLL.</p>
<p><strong> Exercise </strong> Plot the lines calculated from the regression for
each of these independent variables.  Do they fit the models?</p>
<p><strong> Exercise </strong> Run the correlation for % of children eligible for
school lunches.  Is it significant?  Positively or negatively
correlated?  How does this R-squared value compare to the ones we
just calculated?</p>
<h3>Explaining R-squared</h3>

<p>R-squared roughly tells us how well the linear model (the line) we
get from a linear regression explains the independent variable.</p>
<p>R-squared values have <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination">several
interpretations</a>,
but one of them is as the square of a value called <a href="https://en.wikipedia.org/wiki/Pearson_product-moment_correlation_coefficient">the Pearson
Correlation
Coefficient</a>.
That last link has a useful <a href="https://en.wikipedia.org/wiki/File:Correlation_examples2.svg">picture of the correlation
coefficient</a>
that shows you the value of R for different kinds of data.</p>
<p>Squaring R makes it always positive and changes its asymptotic
properties, but the same trends (being near 0 or near 1) still
apply.</p>
<h3>Running Multiple Variables</h3>

<p>So far, we've been able to explain about 50% of the variance in YPLL
using our additional measures data.  Can we do better?  What if we
combine information from multiple measures?  That's called a
multiple regression, and we already have all the tools we need to do
it!  Let's combine household income, %Diabetes, and percentage of
the population under 18 into one regression.</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="n">dependent_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;YPLL Rate&quot;</span><span class="p">]</span>
<span class="n">independent_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s">&quot;&lt; 18&quot;</span><span class="p">,</span> <span class="s">&quot;%Diabetes&quot;</span> <span class="p">,</span> <span class="s">&quot;median household income&quot;</span><span class="p">]</span>
<span class="n">ypll_arr</span><span class="p">,</span> <span class="n">measures_arr</span> <span class="o">=</span> <span class="n">get_arrs</span><span class="p">(</span><span class="n">dependent_cols</span><span class="p">,</span> <span class="n">independent_cols</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">ols</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="n">ypll_arr</span><span class="p">,</span> <span class="n">measures_arr</span><span class="p">,</span> <span class="s">&quot;YPLL Rate&quot;</span><span class="p">,</span> <span class="n">independent_cols</span><span class="p">)</span>
<span class="k">print</span> <span class="s">&quot;p-value&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">Fpv</span>
<span class="k">print</span> <span class="s">&quot;coefficients&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">b</span>
<span class="k">print</span> <span class="s">&quot;R-squared and adjusted R-squared:&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">R2</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">R2adj</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-12'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>We got the following output:</p>
<pre><code> p-value 1.11022302463e-16  
 coefficients [  4.11471809e+03   1.30775027e+02   5.16355557e+02  -8.76770577e-02]  
 R-squared and adjusted R-squared: 0.583249144589 0.582809842914
</code></pre>
<p>So we're still significant, and can read the rest of the output.  A
read of the beta coefficients suggests the best linear combination
of all of these variables is <strong> YPLL = 4115 + 131<em>(% under 18) + 516</em>(% Diabetes) - 877*(median household income) </strong>.</p>
      </div>
      
    </tr><tr id='section-13'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>Because there are multiple independent variables in this regression,
we should look at the adjusted R-squared value, which is .583.  This
value penalizes you for needlessly adding variables to the
regression that don't give you more information about YPLL.  Anyway,
check out that R-squared---nice!  That's larger than the Rsquare value
for any one of the regressions we ran on their own!  We can explain
more of YPLL with these variables.</p>
<p><strong> Exercise </strong> Try combining other variables.  What's the largest
adjusted R-squares you can achieve?  We can reach .715 by an
excessive use of variables.  Can you replicate that?</p>
<h3>Nonlinearity</h3>

<p>Is finding a bunch of independent variables and performing linear
regression against some dependent variable the best we can do to
model our data?  Nope!  Linear regression gives us the best line to
fit through the data, but there are cases where the interaction
between two variables is nonlinear.  In these cases, the
scatterplots we built before matter quite a bit!</p>
<p>Take gravity for example.  Say we measured the distance an object
fell in a certain amount of time, and had a bit of noise to our
measurement.  Below, we'll simulate that activity by generating the
time-distance relationship that we learned in high school.  Imagine
we record the displacement of a ball as we drop it, storing the time
and displacement measurements in <code>timings</code> and <code>displacements</code>.</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="n">timings</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">displacements</span> <span class="o">=</span> <span class="p">[</span><span class="mf">4.9</span><span class="o">*</span><span class="n">t</span><span class="o">*</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">timings</span><span class="p">]</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-14'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>A scatterplot of the data looks like a parabola, which doesn't take
lines very well!  We can <strong> transform </strong> this data by squaring the
time values.</p>
      </div>
      <div class=code>
        <div class='highlight'><pre><div class="highlight"><pre><span class="n">sq_timings</span> <span class="o">=</span> <span class="p">[</span><span class="n">t</span><span class="o">*</span><span class="n">t</span> <span class="k">for</span> <span class="n">t</span> <span class="ow">in</span> <span class="n">timings</span><span class="p">]</span>

<span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">subplot</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">211</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">timings</span><span class="p">,</span> <span class="n">displacements</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#1f77b4&quot;</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;original measurements (parabola)&quot;</span><span class="p">)</span>

<span class="n">subplot</span> <span class="o">=</span> <span class="n">fig</span><span class="o">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">212</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">sq_timings</span><span class="p">,</span> <span class="n">displacements</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">&quot;#1f77b4&quot;</span><span class="p">)</span>
<span class="n">subplot</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">&quot;original measurements (parabola)&quot;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">savefig</span><span class="p">(</span><span class="s">&#39;figures/parabola-linearized.png&#39;</span><span class="p">,</span> <span class="n">format</span><span class="o">=</span><span class="s">&#39;png&#39;</span><span class="p">)</span></pre></div></pre></div>
      </div>
    </tr><tr id='section-15'>
      <div class=docs>
        <div class="octowrap">
          <a class="octothorpe" href="#section-">#</a>
        </div>
        <p>Here are scatterplots of the original and transformed datasets.  You
can see that squaring the time values turned the plot into a more
linear one.</p>
<p><img alt="Original vs. Transformed Data" src="figures/parabola-linearized.png" /></p>
<p><strong> Exercise </strong> Perform a linear regression on the original and
transformed data.  Are they all significant?  What's the R-squared
value of each?  Which model would you prefer?  Does the coefficient
of the transformed value mean anything to you?</p>
<p>For those keeping score at home, we got R-squared of .939 and 1.00
for the unadjusted and adjusted timings, which means we were able to
perfectly match the data after transformation.  Note that in the
case of the squared timings, the equation we end up with is <strong>
displacement = 4.9 * time^2 </strong>, which is the exact formula we had
for gravity.  Awesome!</p>
<p><strong> Exercise </strong> Can you improve the R-squared values by
transformation in the county health rankings?  Try taking the log of
the population, a common technique for making data that is bunched
up spread out more.  To understand what the log transform did, take
a look at a scatterplot.</p>
<p>Log-transforming population got us from R-squared = .026 to
R-squared = .097.</p>
<p>Linear regression, scatterplots, and variable transformation can get
you a long way.  But sometimes, you just can't figure out the right
transformation to perform even though there's a visible relationship
in the data.  In those cases, more complex technques like <a href="https://en.wikipedia.org/wiki/Non-linear_least_squares">nonlinear
least
squares</a> can
fit all sorts of nonlinear functions to the data.</p>
<h3>Eliminate Free Lunches, Save the Planet</h3>

<p>At some point in performing a regression and testing for a
correlation, you will be tempted to come up with solutions to
problems the regression has not identified.  For example, we noticed
that the percentage of children eligible for free lunch is pretty
strongly correlated with the morbidity rate in a community.  How can
we use this knowledge to lower the morbidity rate?</p>
<p><strong> ALERT, ALERT, ALERT!!! </strong> The question at the end of the last
paragraph jumped from correlation to causation.</p>
<p>It would be far-fetched to think that increasing or decreasing the
number of children * eligible * for school lunches would increase or
decrease the morbidity rate in any significant way.  What the
correlation likely means is that there is a third variable, such as
available healthcare, nutrition options, or overall prosperity of a
community that is correlated with both school lunch eligibility and
the morbidity rate.  That's a variable policymakers might have
control over, and if we somehow improved outcomes on that third
variable, we'd see both school lunch eligibility and the morbidity
rate go down.</p>
<p>Remember: correlation means two variables move together, not that
one moves the other.</p>
<h3>ANOVA, Logistic Regression, Machine Learning</h3>

<p>Today you've swallowed quite a bit.  You learned about significance
testing to support or reject high-likelihood meaningful hypotheses.
You learned about the T-Test to help you compare two communities on
whom you've measured data.  You then learned about regression and
correlation, for identifying variables that change together.  From
here, there are several directions to grow.</p>
<ul>
<li>
<p>A more general form of the T-Test is an
<a href="https://en.wikipedia.org/wiki/Analysis_of_variance">ANOVA</a>, where
you can identify differences among more than two groups, and control
for known differences between items in each dataset.</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Logistic_regression">Logistic
regression</a>, and
more generally
<a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a>,
can take a bunch of independent variables and map them onto binary
values.  For example, you could take all of the additional measures
for an individual and predict whether they will die before the age
of 75.</p>
</li>
<li>
<p><a href="https://en.wikipedia.org/wiki/Machine_learning">Machine
 learning</a> and <a href="https://en.wikipedia.org/wiki/Data_mining">data
 mining</a> are fields that
 assume statistical significance (you collect boatloads of data) and
 develop algorithms to classify, cluster, and otherwise find
 patterns in the underlying datasets.</p>
</li>
</ul>
      </div>
      
    </tr>
  </table>
</div>
</body>
